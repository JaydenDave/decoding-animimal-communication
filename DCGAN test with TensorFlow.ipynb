{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b079d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks,\n",
    "    losses,\n",
    "    utils,\n",
    "    metrics,\n",
    "    optimizers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72ab4b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow **IS NOT** using the GPU\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"TensorFlow **IS** using the GPU\")\n",
    "else:\n",
    "  print(\"TensorFlow **IS NOT** using the GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d00b1",
   "metadata": {},
   "source": [
    "Creating a TF dataset from image files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fce8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#lego brick dataset\n",
    "directory = r\"C:\\Users\\Jayde\\Desktop\\lego-brick-data\\dataset\"\n",
    "#also resizes the images to 64x64 (from 400x400), interpolating between pixel values\n",
    "train_data = utils.image_dataset_from_directory(directory,\n",
    "                                               labels=None,\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               image_size=(64,64),\n",
    "                                               batch_size=128,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42,\n",
    "                                               interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c08f4a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c346a9e4c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = train_data.take(1).get_single_element()\n",
    "#this takes 1 batch, sample.shape = [128,64,64,1] = [n_batches,xdim,ydim,channels]\n",
    "sample=sample[0] #one sample out of the batch\n",
    "sample=sample.numpy() #tensorflow tensor to numpy array\n",
    "plt.imshow(sample, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8edb668",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    ". Rescaling from [0,255] to [-1,1] (so we can use tanh activation function on final layer of generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58e63807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img= (tf.cast(img,\"float32\") - 127.5) / 127.5 #tf.cast changes the tensor datatype \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7642d1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train_data.map(lambda x: preprocess(x))\n",
    "train = train_data.map(preprocess)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee94885",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a43e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_input =layers.Input(shape = (64,64,1)) #input layer shape (size, channels (1 for greyscale))\n",
    "x = layers.Conv2D(64, kernel_size = 4, strides = 2, padding= \"same\", use_bias = False)(dis_input)\n",
    "#conv layer 64 channels (increased from 1), strides of 2 halves spacial tensor size (64 -> 32)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x) # for dropout regularization\n",
    "\n",
    "#32\n",
    "x = layers.Conv2D(128, kernel_size = 4, strides = 2, padding= \"same\", use_bias = False)(x)\n",
    "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "#16\n",
    "x = layers.Conv2D(256, kernel_size = 4, strides = 2, padding= \"same\", use_bias = False)(x)\n",
    "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "#8\n",
    "x = layers.Conv2D(512, kernel_size = 4, strides = 2, padding= \"same\", use_bias = False)(x)\n",
    "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "#4\n",
    "#final conv layer with sigmoid activation to output a number between 0 and 1\n",
    "x = layers.Conv2D(1, kernel_size = 4, strides = 1, padding= \"valid\", use_bias = False, activation = 'sigmoid')(x)\n",
    "\n",
    "#flatten the last conv layer (shape of 1,1,1 to 1d array)\n",
    "dis_output = layers.Flatten()(x)\n",
    "\n",
    "discriminator = models.Model(dis_input, dis_output, name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f018f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1024      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131072    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 256)         524288    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 512)         2097152   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 1, 1)           8192      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,765,312\n",
      "Trainable params: 2,763,520\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c68fc",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c345702",
   "metadata": {},
   "source": [
    "The input to the generator is a vector drwan from a mulitivariate standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bbf3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = layers.Input(shape=(100,)) # input vector of legnth 100\n",
    "x = layers.Reshape((1,1,100))(gen_input) # now a 1x1x100 tensor, can now apply convolutional transpose operations\n",
    "\n",
    "#basically now just the reverse of the discriminator\n",
    "x= layers.Conv2DTranspose(512, kernel_size=4, strides=1, padding=\"valid\", use_bias= False)(x)\n",
    "x= layers.BatchNormalization(momentum=0.9)(x)\n",
    "x= layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "x= layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\", use_bias= False)(x)\n",
    "x= layers.BatchNormalization(momentum=0.9)(x)\n",
    "x= layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "x= layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", use_bias= False)(x)\n",
    "x= layers.BatchNormalization(momentum=0.9)(x)\n",
    "x= layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "x= layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", use_bias= False)(x)\n",
    "x= layers.BatchNormalization(momentum=0.9)(x)\n",
    "x= layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "#tanh activation to transform the output to range [-1,1] to match the origional domain\n",
    "gen_output = layers.Conv2DTranspose(1, kernel_size = 4, strides=2, padding = \"same\", use_bias = False, activation = 'tanh')(x)\n",
    "\n",
    "generator = models.Model(gen_input, gen_output, name= \"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339b6ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 1, 100)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 4, 4, 512)        819200    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 8, 8, 256)        2097152   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 16, 16, 128)      524288    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 32, 64)       131072    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 64, 64, 1)        1024      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,576,576\n",
      "Trainable params: 3,574,656\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a99c1",
   "metadata": {},
   "source": [
    "Alternative to conv2d transpose layers is to use upsampling2d followed my normal conv2d layer with stride 1.\n",
    "\n",
    "x = layers.UpSampling2D(size = 2)(x)\n",
    "\n",
    "x= layers.Conv2D(256, kernel_size=4, strides=1, padding=\"same\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8facaf2a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce27ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(models.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.loss_fn = losses.BinaryCrossentropy()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_metric = metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = self.generator(\n",
    "                random_latent_vectors, training = True\n",
    "            )\n",
    "            real_predictions = self.discriminator(real_images, training = True)\n",
    "            fake_predictions = self.discriminator(generated_images, training = True)\n",
    "            \n",
    "            real_labels = tf.ones_like(real_predictions) #creates a tensor with shape of real_predictions with all values set to 1\n",
    "            #label smoothing\n",
    "            real_noisy_labels = real_labels + 0.1*tf.random.uniform(tf.shape(real_predictions))\n",
    "            \n",
    "            fake_labels = tf.zeros_like(fake_predictions)\n",
    "            fake_noisy_labels = fake_labels + 0.1*tf.random.uniform(tf.shape(fake_predictions))\n",
    "            \n",
    "            d_real_loss = self.loss_fn(real_noisy_labels, real_predictions)\n",
    "            d_fake_loss = self.loss_fn(fake_noisy_labels, fake_predictions)\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2.0\n",
    "            \n",
    "            g_loss = self.loss_fn(real_labels, fake_predictions)\n",
    "        \n",
    "        gradients_of_discriminator = disc_tape.gradient(\n",
    "            d_loss, self.discriminator.trainable_variables\n",
    "        )\n",
    "        gradients_of_generator = gen_tape.gradient(\n",
    "            g_loss, self.generator.trainable_variables\n",
    "        )\n",
    "        \n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(gradients_of_discriminator, discriminator.trainable_variables)\n",
    "        )\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gradients_of_generator, generator.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a628734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 14/313 [>.............................] - ETA: 44:41 - d_loss: 0.1300 - g_loss: 2.1020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32332\\2125907052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdcgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Jayde\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jayde\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1683\u001b[0m                         ):\n\u001b[0;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jayde\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jayde\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jayde\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    924\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jayde\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m       (concrete_function,\n\u001b[0;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jayde\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1756\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1757\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\Jayde\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jayde\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dcgan = DCGAN(discriminator = discriminator, generator = generator, latent_dim=100)\n",
    "\n",
    "dcgan.compile(\n",
    "    d_optimizer = optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5, beta_2 = 0.999),\n",
    "    g_optimizer = optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5, beta_2 = 0.999)\n",
    ")\n",
    "\n",
    "dcgan.fit(train, epochs=100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea95fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
