{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks,\n",
    "    losses,\n",
    "    utils,\n",
    "    metrics,\n",
    "    optimizers,\n",
    ")\n",
    "from preprocess import load_raw_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow **IS NOT** using the GPU\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"TensorFlow **IS** using the GPU\")\n",
    "else:\n",
    "  print(\"TensorFlow **IS NOT** using the GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 64\n",
    "CHANNELS = 1 #keeping as 1? what for mono or stereo?\n",
    "PHASE_PARAM = 2\n",
    "LATENT_DIM = 100\n",
    "DISCRIMINATOR_STEPS = 5\n",
    "GP_WEIGHT = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.9\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_mul = 16\n",
    "gen_input = layers.Input(shape=(100,)) # input vector of legnth 100 (z sampled from uniform normal dist)\n",
    "x = layers.Dense(units = 4*4*dim_mul*DIM, use_bias = True)(gen_input)\n",
    "x = layers.Reshape((16,dim_mul*DIM))(x)\n",
    "x = layers.ReLU()(x)\n",
    "dim_mul //=2\n",
    "\n",
    "x = layers.Conv1DTranspose(filters = dim_mul*DIM, strides = 4, padding= \"same\", kernel_size = 25, use_bias = True)(x)\n",
    "x = layers.ReLU()(x)\n",
    "dim_mul //=2\n",
    "\n",
    "x = layers.Conv1DTranspose(filters = dim_mul*DIM, strides = 4, padding= \"same\", kernel_size = 25, use_bias = True)(x)\n",
    "x = layers.ReLU()(x)\n",
    "dim_mul //=2\n",
    "\n",
    "x = layers.Conv1DTranspose(filters = dim_mul*DIM, strides = 4, padding= \"same\", kernel_size = 25, use_bias = True)(x)\n",
    "x = layers.ReLU()(x)\n",
    "dim_mul //=2\n",
    "\n",
    "x = layers.Conv1DTranspose(filters = dim_mul*DIM, strides = 4, padding= \"same\", kernel_size = 25, use_bias = True)(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "gen_output = layers.Conv1DTranspose(filters = CHANNELS, strides = 4, padding= \"same\", kernel_size = 25, use_bias = True, activation = 'tanh')(x)\n",
    "\n",
    "generator = models.Model(gen_input, gen_output, name= \"generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16384)             1654784   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 1024)          0         \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 16, 1024)          0         \n",
      "                                                                 \n",
      " conv1d_transpose (Conv1DTra  (None, 64, 512)          13107712  \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 64, 512)           0         \n",
      "                                                                 \n",
      " conv1d_transpose_1 (Conv1DT  (None, 256, 256)         3277056   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 256, 256)          0         \n",
      "                                                                 \n",
      " conv1d_transpose_2 (Conv1DT  (None, 1024, 128)        819328    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 1024, 128)         0         \n",
      "                                                                 \n",
      " conv1d_transpose_3 (Conv1DT  (None, 4096, 64)         204864    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 4096, 64)          0         \n",
      "                                                                 \n",
      " conv1d_transpose_4 (Conv1DT  (None, 16384, 1)         1601      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,065,345\n",
      "Trainable params: 19,065,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrimniator\n",
    "Need to define a phase shuffle layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseShuffle(layers.Layer):\n",
    "    def call(self, x):\n",
    "        n= PHASE_PARAM\n",
    "        b, x_len, nch = x.get_shape().as_list()\n",
    "        phase = tf.random.uniform([], minval=-n, maxval=n + 1, dtype=tf.int32)\n",
    "        pad_l = tf.maximum(phase, 0)\n",
    "        pad_r = tf.maximum(-phase, 0)\n",
    "        phase_start = pad_r\n",
    "        x = tf.pad(x, [[0, 0], [pad_l, pad_r], [0, 0]], mode='reflect')\n",
    "\n",
    "        x = x[:, phase_start:phase_start+x_len]\n",
    "        x.set_shape([b, x_len, nch])\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_mul = 16\n",
    "dis_input = layers.Input(shape = (dim_mul*dim_mul*DIM, CHANNELS,), name = \"discriminator_input\")\n",
    "x = layers.Conv1D(filters = DIM, strides = 4, kernel_size = 25, padding = \"same\", use_bias = True)(dis_input)\n",
    "x = layers.LeakyReLU(alpha = 0.2)(x)\n",
    "x = PhaseShuffle()(x)\n",
    "\n",
    "x = layers.Conv1D(filters = 2*DIM, strides = 4, kernel_size = 25, padding = \"same\", use_bias = True)(x)\n",
    "x = layers.LeakyReLU(alpha = 0.2)(x)\n",
    "x = PhaseShuffle()(x)\n",
    "\n",
    "x = layers.Conv1D(filters = 4*DIM, strides = 4, kernel_size = 25, padding = \"same\", use_bias = True)(x)\n",
    "x = layers.LeakyReLU(alpha = 0.2)(x)\n",
    "x = PhaseShuffle()(x)\n",
    "\n",
    "x = layers.Conv1D(filters = 8*DIM, strides = 4, kernel_size = 25, padding = \"same\", use_bias = True)(x)\n",
    "x = layers.LeakyReLU(alpha = 0.2)(x)\n",
    "x = PhaseShuffle()(x)\n",
    "\n",
    "x = layers.Conv1D(filters = dim_mul*DIM, strides = 4, kernel_size = 25, padding = \"same\", use_bias = True)(x)\n",
    "x = layers.LeakyReLU(alpha = 0.2)(x)\n",
    "#x = layers.Reshape((4*4*dim_mul*DIM))(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "dis_output = layers.Dense(units = 1, use_bias = True)(x)\n",
    "discriminator = models.Model(dis_input, dis_output, name=\"discriminator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " discriminator_input (InputL  [(None, 16384, 1)]       0         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 4096, 64)          1664      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 4096, 64)          0         \n",
      "                                                                 \n",
      " phase_shuffle (PhaseShuffle  (None, 4096, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1024, 128)         204928    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 1024, 128)         0         \n",
      "                                                                 \n",
      " phase_shuffle_1 (PhaseShuff  (None, 1024, 128)        0         \n",
      " le)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 256, 256)          819456    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 256, 256)          0         \n",
      "                                                                 \n",
      " phase_shuffle_2 (PhaseShuff  (None, 256, 256)         0         \n",
      " le)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 64, 512)           3277312   \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 64, 512)           0         \n",
      "                                                                 \n",
      " phase_shuffle_3 (PhaseShuff  (None, 64, 512)          0         \n",
      " le)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 16, 1024)          13108224  \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 16, 1024)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 16385     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,427,969\n",
      "Trainable params: 17,427,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGAN(models.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim, discriminator_steps, gp_weight):\n",
    "        super(WaveGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.discriminator_steps = discriminator_steps\n",
    "        self.gp_weight = gp_weight\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(WaveGAN, self).compile()\n",
    "        self.loss_fn = losses.BinaryCrossentropy()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_wass_loss_metric = metrics.Mean(name = \"d_wass_loss\")\n",
    "        self.d_gp_metric = metrics.Mean(name = \"d_gp\")\n",
    "        self.d_loss_metric = metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.d_loss_metric,\n",
    "            self.g_loss_metric,\n",
    "            self.d_gp_metric,\n",
    "            self.d_wass_loss_metric,\n",
    "            ]\n",
    "    \n",
    "    def gradient_penalty(self, batch_size, real_data, fake_data):\n",
    "        alpha = tf.random.normal([batch_size, 1, 1], 0.0, 1.0) # each audio file in the batch gets a random number between 0 and 1, stored as the vector alpha\n",
    "        diff = fake_data - real_data\n",
    "        interpolated = real_data +alpha*diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            pred = self.discriminator(interpolated, training = True)\n",
    "\n",
    "        #gradient of the preds wrt the inputs\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "\n",
    "        norm= tf.sqrt(tf.reduce_sum(tf.square(grads), axis = [1,2]))\n",
    "        gp = tf.reduce_mean((norm -1.0)**2) #returns avg square distance between L2 norm and 1\n",
    "        return gp\n",
    "    \n",
    "\n",
    "    def train_step(self, real_data):\n",
    "        batch_size = tf.shape(real_data)[0]\n",
    "\n",
    "        #update discriminator a few times\n",
    "        for i in range(self.discriminator_steps):\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                generated_data = self.generator(random_latent_vectors, training = True)\n",
    "                generated_predictions = self.discriminator(generated_data, training = True)\n",
    "                real_predictions = self.discriminator(real_data, training = True)\n",
    "\n",
    "                d_wass_loss = tf.reduce_mean(generated_predictions) - tf.reduce_mean(real_predictions)\n",
    "                d_gp = self.gradient_penalty(batch_size, real_data, generated_data)\n",
    "                d_loss = d_wass_loss + d_gp*self.gp_weight\n",
    "            \n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n",
    "        \n",
    "        #update generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_data = self.generator(random_latent_vectors, training = True)\n",
    "            generated_predictions = self.discriminator(generated_data, training = True)\n",
    "            g_loss = -tf.reduce_mean(generated_predictions)\n",
    "\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n",
    "            \n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.d_wass_loss_metric.update_state(d_wass_loss)\n",
    "        self.d_gp_metric.update_state(d_gp)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan = WaveGAN(\n",
    "    discriminator = discriminator,\n",
    "    generator= generator,\n",
    "    latent_dim = LATENT_DIM,\n",
    "    discriminator_steps= DISCRIMINATOR_STEPS,\n",
    "    gp_weight= GP_WEIGHT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan.compile(\n",
    "    d_optimizer = optimizers.Adam(learning_rate=LEARNING_RATE, beta_1 = ADAM_BETA_1, beta_2 = ADAM_BETA_2),\n",
    "    g_optimizer = optimizers.Adam(learning_rate=LEARNING_RATE, beta_1 = ADAM_BETA_1, beta_2 = ADAM_BETA_2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint\",\n",
    "    save_weights_only=False,\n",
    "    save_freq=\"epoch\",\n",
    "    monitor=\"loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    verbose=0,\n",
    ")\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa as lb\n",
    "\n",
    "def load_raw_audio(data_path):\n",
    "    audio = []\n",
    "    for folder in os.listdir(data_path):\n",
    "        path = os.path.join(data_path, folder)\n",
    "        for file in os.listdir(path):\n",
    "            file_path = os.path.join(path, file)\n",
    "            signal, sr = lb.load(file_path)\n",
    "            #22050\n",
    "            signal = set_duration(signal, max = 16384)\n",
    "            #print(signal.dtype)\n",
    "            #print(signal.shape)\n",
    "            audio.append(signal)\n",
    "        print(f\"Loaded audio from {folder}\")\n",
    "    break\n",
    "    print(f\"Loaded audio from {data_path}\")\n",
    "    return audio\n",
    "\n",
    "def pad_audio(signal, max):\n",
    "    if len(signal) < max:\n",
    "        num_missing_samples = max - len(signal)\n",
    "        padded_array = np.pad(signal,\n",
    "                              (0,num_missing_samples),\n",
    "                              mode = \"constant\")\n",
    "        return padded_array\n",
    "    return signal\n",
    "\n",
    "def set_duration(signal, max):\n",
    "    if len(signal) < max:\n",
    "        num_missing_samples = max - len(signal)\n",
    "        padded_array = np.pad(signal,\n",
    "                              (0,num_missing_samples),\n",
    "                              mode = \"constant\")\n",
    "        return padded_array\n",
    "    else:\n",
    "        signal = signal[:max]\n",
    "    return signal\n",
    "from scipy import signal\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    normalized_audio = [signal.rescale(s, 1.0 / max(abs(s))) for s in audio]\n",
    "    return normalized_audio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded audio from eight\n",
      "Loaded audio from C:\\Users\\Jayde\\Desktop\\Datasets\\sc09\\sc09\n",
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Jayde\\Desktop\\Datasets\\sc09\\sc09\"\n",
    "train_data = load_raw_audio(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/60 [>.............................] - ETA: 2:53:41 - d_loss: 3.3818 - g_loss: -0.1741 - d_gp: 0.4613 - d_wass_loss: -1.2316    "
     ]
    }
   ],
   "source": [
    "wavegan.fit(\n",
    "    train_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        tensorboard_callback\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
